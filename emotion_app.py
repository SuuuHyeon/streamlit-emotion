# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mKKxL7s6WIJJ-7s3SethVWvP7O3dGMPH
"""

import streamlit as st
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase
import cv2
import numpy as np
from deepface import DeepFace
import av # streamlit-webrtc를 위한 PyAV 라이브러리

st.set_page_config(page_title="실시간 감정 분류기", page_icon="😊")

st.title("🧠 실시간 감정 분류기")
st.write("노트북 카메라를 통해 당신의 감정을 실시간으로 분석합니다.")
st.write("카메라를 켜고 잠시 기다리면 얼굴을 인식하고 감정을 표시합니다.")

# 감정 분석 및 화면에 그리는 로직을 담는 클래스
class EmotionVideoTransformer(VideoTransformerBase):
    def __init__(self):
        # 얼굴 탐지를 위한 Haar Cascade 분류기 로드
        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        self.emotion_cache = {} # 간단한 캐시로 감정 분석 호출 줄이기

    def transform(self, frame: av.VideoFrame) -> np.ndarray:
        img = frame.to_ndarray(format="bgr24")
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        # 얼굴 탐지
        faces = self.face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

        for (x, y, w, h) in faces:
            # 얼굴 영역 추출
            face_roi = img[y:y + h, x:x + w]

            try:
                # DeepFace를 사용하여 감정 분석
                # enforce_detection=False: 이미 얼굴을 찾았으므로 재탐지 안함
                analysis = DeepFace.analyze(face_roi, actions=['emotion'], enforce_detection=False)

                # DeepFace 2.0 이상에서는 analysis가 리스트 형태로 반환됨
                if isinstance(analysis, list):
                    emotion = analysis[0]['dominant_emotion']
                else: # 이전 버전 호환성
                    emotion = analysis['dominant_emotion']

                # 감정을 영어에서 한글로 변환 (선택사항)
                emotion_map = {
                    'angry': '분노', 'disgust': '혐오', 'fear': '두려움',
                    'happy': '행복', 'sad': '슬픔', 'surprise': '놀람', 'neutral': '중립'
                }
                emotion_korean = emotion_map.get(emotion, emotion)

                # 얼굴 주위에 사각형 그리기
                cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)

                # 감정 텍스트 표시
                font = cv2.FONT_HERSHEY_SIMPLEX
                cv2.putText(img, emotion_korean, (x, y - 10), font, 0.9, (255, 0, 0), 2)

            except Exception as e:
                # 얼굴이 너무 작거나 각도가 안 맞아 분석이 실패할 경우 무시
                pass

        return img

# Streamlit-webrtc 위젯
webrtc_ctx = webrtc_streamer(
    key="emotion-classifier",
    video_transformer_factory=EmotionVideoTransformer,
    rtc_configuration={  # ICE 서버 설정 (배포 시 필요할 수 있음)
        "iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]
    },
    media_stream_constraints={"video": True, "audio": False},
    async_processing=True,
)

st.info("앱이 시작되면 브라우저에서 카메라 접근 권한을 허용해주세요.")